{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f39f3-2b23-447a-a4aa-8213df24acbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install yandex-cloud-ml-sdk --upgrade --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74266c12-60ed-4a0f-bc7e-4c3f18cf5aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib \n",
    "\n",
    "def local_path(path: str) -> pathlib.Path:\n",
    "    return pathlib.Path(path)\n",
    "\n",
    "dataset_path = local_path(\"generations.jsonlines\")\n",
    "print(dataset_path)\n",
    "\n",
    "print(\"Данные датасета для дообучения\")\n",
    "print(dataset_path.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576203cd-624b-4a26-af1a-c6ae719d793c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "from __future__ import annotations\n",
    "\n",
    "from yandex_cloud_ml_sdk import YCloudML\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "\n",
    "\n",
    "def download_tensorboard(url):\n",
    "    urllib.request.urlretrieve(url, \"tensorboard.zip\")\n",
    "    with zipfile.ZipFile('tensorboard.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"tensorboard\")\n",
    "\n",
    "\n",
    "def train() -> None:\n",
    "    \n",
    "    # Создаем объект SDK, содержащий параметры для авторизации\n",
    "    # Авторизация происходит от имени сервисного аккаунта с ролью ai.editor\n",
    "    # Для аутентификации используется API-ключ \n",
    "    \n",
    "    sdk = YCloudML(\n",
    "        folder_id=os.environ['FOLDER_ID'], # Идентификатор каталога, сохраненный в секрете DataSphere\n",
    "        auth=os.environ['API_KEY'] # API-ключ сервисного аккаунта, сохраненный в секрете DataSphere\n",
    "    )\n",
    "    \n",
    "    print('Создаем датасет для дообучения')\n",
    "\n",
    "    # Создаем датасет для дообучения модели генерации текса\n",
    "    # Указываем путь к файлу с данными, формат и тип датасета\n",
    "    dataset_draft = sdk.datasets.draft_from_path(\n",
    "        task_type='TextToTextGeneration',\n",
    "        path=dataset_path,\n",
    "        upload_format='jsonlines',\n",
    "        name='test-generations'\n",
    "    )\n",
    "\n",
    "    # Запускаем загрузку и валидацию датасета, дожидаемся окончания\n",
    "    operation = dataset_draft.upload()\n",
    "    print('Датасет загружается и валидируется')\n",
    "    dataset = operation.wait()\n",
    "    print(f'Новый датасет {dataset=} \\n')\n",
    "\n",
    "\n",
    "    # Выбираем базовую модель, которую хотим дообучить. В примере — Llama lite\n",
    "    base_model = sdk.models.completions('llama-lite')\n",
    "\n",
    "    # Запускаем дообучение модели\n",
    "    tuning_task = base_model.tune_deferred(\n",
    "        dataset,\n",
    "        name=str(uuid.uuid4()),\n",
    "        n_samples=10000 \n",
    "    )\n",
    "    \n",
    "    print(f'Обучение началось {tuning_task} \\n')\n",
    "\n",
    "    # Дожидаемся завершения операции обучения и получаем новую модель\n",
    "    new_model = tuning_task.wait()\n",
    "    print(f'Обучение закончилось, новая модель = {new_model} \\n')\n",
    "    \n",
    "    # Получаем ссылку с данными для тензорборда и скачиваем файлы\n",
    "    metrics_url = tuning_task.get_metrics_url()\n",
    "    download_tensorboard(metrics_url)\n",
    "\n",
    "    print('Посылаем запросы в новую модель\\n')\n",
    "    # Примеры запросов в модель\n",
    "    completion_result = new_model.run(\"Как тебя зовут?\")\n",
    "    print(f'{completion_result=} \\n')\n",
    "\n",
    "    # Дообученную модель можно использовать, указав ее URI\n",
    "    tuned_uri = new_model.uri \n",
    "    model = sdk.models.completions(tuned_uri)\n",
    "\n",
    "    completion_result = model.run(\"Откуда ты?\")\n",
    "    print(f'{completion_result=} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b408e-7d5e-4e39-a782-0a88ff55d889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29372b41-1189-4a72-86ec-ac78c5750bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
